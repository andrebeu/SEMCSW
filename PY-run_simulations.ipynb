{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nick comment on run model\n",
    "The main script we use to run the experiment is  `schema_prediction_task_9_8_20.batch_exp`.  It's a wrapper function for a lot of code,\n",
    "but it will generate a set of randomly sampled tasks of the specified conditions (default = Blocked, Interleaved), run the model (either SEM or a \"no_split\" variant of SEM that collapses to the NN specified) and calculate the meaningful metrics of the task.\n",
    "\n",
    "\n",
    "It's desined to be a parallelizable job on a cluster -- you can pass a set of parameters to the function and get a pair of files as an output that represents a random sample of behavior for those parameters on the specified tasks.  I (NTF) would spawn thousands of instances of this function in seperate SLURM jobs, each with different parameters and write the results to file for grid-searches.  It is possible to get fancier with the paralization by writting a custom wrapper for some of the SEM module (look at the function `no_split_sem.no_split_sem_run_with_boundaries` for ideas) but I chose not to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQ9KSajiwUpk"
   },
   "source": [
    "This script runs one param_set\n",
    "outputs results and trialxtrial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCrz6mCuD6i8"
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.9 (default, Aug 31 2020, 07:22:35) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import logsumexp\n",
    "from scipy.stats import norm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from schema_prediction_task_9_8_20 import generate_exp, batch_exp\n",
    "from vanilla_lstm import VanillaLSTM\n",
    "from sem.event_models import NonLinearEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "seed = None\n",
    "err = 0.2; # error probability for plate's formula\n",
    "\n",
    "# story_generator = generate_exp_balanced\n",
    "\"\"\" \n",
    "actor_weight & instructions_weight \n",
    "control instruction condition\n",
    "\"\"\"\n",
    "story_kwargs = dict(seed=None, err=0.2, actor_weight=1.0, instructions_weight=1.0)\n",
    "\n",
    "x, y, e, embedding_library = generate_exp('blocked', **story_kwargs)\n",
    "print(np.shape(x)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gridsearch params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr                = 0.05\n",
    "n_batch=1\n",
    "no_split = False # toggle between SEM (False) and LSTM (True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sem parameters\n",
    "dropout           = 0.0  # don't change\n",
    "l2_regularization = 0.0  # don't change\n",
    "n_epochs          = 2\n",
    "batch_size        = 25   # don't change\n",
    "\n",
    "epsilon           = 1e-5 # don't change\n",
    "log_alpha         = 0.0  # sCRP alpha is set in log scale\n",
    "log_lambda        = 0.0   # sCRP lambda is set in log scale\n",
    "n_hidden          = None # don't change -- set the number of hidden units equal to the dimensionality\n",
    "batch_update      = False # batch update (True) or local gradient updating (False)\n",
    "\n",
    "\n",
    "# ADAM parameters, don't change\n",
    "optimizer_kwargs = dict(\n",
    "    lr=lr, beta_1=0.9, beta_2=0.999, epsilon=epsilon, amsgrad=False\n",
    ")\n",
    "\n",
    "# set the event model class\n",
    "f_class = VanillaLSTM\n",
    "\n",
    "# the dictionaries below are used to pass the above parameters to SEM\n",
    "f_opts=dict(\n",
    "  batch_size=batch_size, \n",
    "  batch_update=batch_update, \n",
    "  dropout=dropout,\n",
    "  l2_regularization=l2_regularization, \n",
    "  n_epochs=n_epochs,\n",
    "    optimizer_kwargs=optimizer_kwargs\n",
    ")\n",
    "\n",
    "sem_kwargs = dict(lmda=np.exp(log_lambda), alfa=np.exp(log_alpha), f_opts=f_opts, f_class=f_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model\n",
    "\n",
    "main fun call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run SEM:  56%|█████▋    | 113/200 [01:14<01:16,  1.14it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "batch_exp main fun call\n",
    "\"\"\"\n",
    "results, trialXtrial, _ = batch_exp(\n",
    "              sem_kwargs, story_kwargs, \n",
    "              no_split=no_split, block_only=False, run_instructed=False, \n",
    "              sem_progress_bar=True, progress_bar=False,\n",
    "              n_batch=n_batch, \n",
    ")\n",
    "\n",
    "\n",
    "# convert from JSON file format (dict) to pandas df\n",
    "results = pd.DataFrame(results)\n",
    "trialXtrial = pd.DataFrame(trialXtrial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAOkKQ5O8j7f"
   },
   "source": [
    "# save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fpath = None\n",
    "results,trialXtrial"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Fg0K8FUow9Dy",
    "J0shpNw-wRT2"
   ],
   "name": "AndreTask; 2/7/20.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
