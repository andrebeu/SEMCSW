{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "# from CSW import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.3.1\n",
      "TensorFlow Version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from CSWSEM import *\n",
    "from cswRNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "pr = 1.0\n",
    "taskL = [CSWTask(pr),CSWTask(1-pr)]\n",
    "eval_pathL = [\n",
    "  [10,0,1,4,5],       \n",
    "  [11,0,1,3,5],\n",
    "  ]\n",
    "xeval = taskL[0].format_Xeval(eval_pathL)\n",
    "xeval = tr.tensor(xeval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsch = 2\n",
    "seed = np.random.randint(99)\n",
    "model = SEMrep(stsize=40,nschemas=nsch,seed=seed)\n",
    "\n",
    "## task params\n",
    "neps = 200\n",
    "block_len = 40\n",
    "learn_rate = 0.1\n",
    "\n",
    "## train setup\n",
    "softmax = lambda ulog: tr.softmax(ulog,-1)\n",
    "lossop = tr.nn.CrossEntropyLoss()\n",
    "\n",
    "# record\n",
    "lossL,peL = [],[]\n",
    "sch_use = np.zeros([nsch,neps])\n",
    "tdim,sm_dim=5,12\n",
    "ysm = -np.ones([nsch,2,neps,tdim,sm_dim])\n",
    "\n",
    "## train loop\n",
    "task_int = 0\n",
    "for ep in range(neps):\n",
    "  # curriculum: select task\n",
    "  if ep == 160:\n",
    "    block_len = 1\n",
    "  if ep%block_len==0:\n",
    "    task_int = (task_int+1)%2\n",
    "    task = taskL[task_int]\n",
    "    filler_id = 10+task_int \n",
    "  # generate data\n",
    "  path = task.sample_path()\n",
    "  xtrain,ytrain = task.dataset_onestory_with_marker(path=path,filler_id=filler_id,depth=1)\n",
    "  # select net\n",
    "  net = model.select_net(xtrain,ytrain) \n",
    "  sch_use[net.seed-seed,ep] = 1\n",
    "  # eval\n",
    "  for sch_idx,xev in enumerate(xeval):\n",
    "    for net_idx,net in enumerate(model.schlib):\n",
    "      ysm_t = softmax(net(xev)).detach().numpy()\n",
    "      ysm[net_idx,sch_idx,ep] = ysm_t\n",
    "  # forward prop train data\n",
    "  yhat = net(xtrain)\n",
    "  # back prop\n",
    "  pe = model.calc_PE(yhat,ytrain)\n",
    "  peL.append(pe)\n",
    "  loss = 0\n",
    "  optiop = tr.optim.Adam(net.parameters(), lr=learn_rate)\n",
    "  optiop.zero_grad()\n",
    "  for tstep in range(len(xtrain)):\n",
    "    loss += lossop(yhat[tstep].unsqueeze(0),ytrain[tstep])\n",
    "    loss.backward(retain_graph=True)\n",
    "  optiop.step()\n",
    "  lossL.append(loss.detach().numpy())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
