{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "\n",
    "from glob import glob as glob\n",
    "import pandas as pd\n",
    "\n",
    "from CSWSEM import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pd.read_csv('gsdata/humandf.csv')\n",
    "humanB = hdf.loc[:,'blocked mean']\n",
    "humanI = hdf.loc[:,'interleaved mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsname = 'gs2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gsdf(gsname,save=False,debug=False):\n",
    "  gs_dir = \"gsdata/%s/\"%gsname\n",
    "  fpathL = glob(gs_dir+'*')\n",
    "  df_L = []\n",
    "  ### initialize gsdf\n",
    "  if debug: fpathL[:10]\n",
    "  for fpath in fpathL[:10]:\n",
    "    batch_df = pd.read_csv(fpath)\n",
    "    df_L.append(batch_df)\n",
    "  gsdf = pd.concat(df_L)\n",
    "  ### gsdf manipulations\n",
    "  gsdf.index = np.arange(len(gsdf))\n",
    "  gsdf = gsdf.drop(columns=['Unnamed: 0','like','prior'])\n",
    "  gsdf.loc[:,'accuracy'] = 1-gsdf.loc[:,'loss']\n",
    "  gsdf.loc[(gsdf.trial>=160),'phase'] = 'test'\n",
    "  gsdf.loc[(gsdf.trial<160),'phase'] = 'train'\n",
    "  gsdf.loc[:,'period'] = gsdf.trial%5\n",
    "  \n",
    "  if save:\n",
    "    gsdf.to_csv('gsdata/%s.csv'%gsname)\n",
    "    print('saved %s.csv'%gsname)\n",
    "  return gsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved gs2.csv\n",
      "max delta_time 55.34397864341736\n"
     ]
    }
   ],
   "source": [
    "gsdf = make_gsdf(gsname,save=1,debug=0)\n",
    "gsdf = pd.read_csv('gsdata/%s.csv'%gsname)\n",
    "print('max delta_time',gsdf.delta_time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dataD(gsdf,metric='loss',verb=True):\n",
    "  \"\"\" extracts and reformats a column of gsdf\n",
    "  D[model+param_str][cond] = [seed,time]\n",
    "  \"\"\"\n",
    "  paramL = ['learn_rate','alfa','lmda']\n",
    "  dataD = {}\n",
    "  for nosplit,m_df in gsdf.groupby(['nosplit']):  \n",
    "    if nosplit: model='LSTM'\n",
    "    else: model='SEM'\n",
    "    for p,p_df in m_df.groupby(paramL):\n",
    "      param_str = \"-\".join([str(p_i) for p_i in p])\n",
    "      dataD_key = \"%s-%s\"%(model,param_str)\n",
    "      dataD[dataD_key] = {}\n",
    "      for cond,c_df in p_df.groupby('condition'):\n",
    "        if verb: print(model,param_str,cond)\n",
    "        sgroup = c_df.groupby('seed')\n",
    "        seed_arr = -np.ones([len(sgroup),200])\n",
    "        for s_idx,(s,s_df) in enumerate(sgroup):\n",
    "          seed_arr[s_idx] = s_df.loc[:,metric]\n",
    "        dataD[dataD_key][cond] = seed_arr\n",
    "  return dataD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num model conditions 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['SEM-0.01-0.01-0.1', 'SEM-0.05-1.0-1.0', 'SEM-0.05-10.0-0.1', 'SEM-0.05-100.0-0.01', 'SEM-0.05-10000.0-0.01', 'SEM-0.05-100000.0-100000.0', 'SEM-0.1-0.01-100000.0', 'SEM-0.1-0.1-0.01', 'SEM-0.1-1.0-0.1', 'SEM-0.1-1000.0-0.1', 'LSTM-0.01-0.01-0.1', 'LSTM-0.05-1.0-1.0', 'LSTM-0.05-10.0-0.1', 'LSTM-0.05-100.0-0.01', 'LSTM-0.05-10000.0-0.01', 'LSTM-0.05-100000.0-100000.0', 'LSTM-0.1-0.01-100000.0', 'LSTM-0.1-0.1-0.01', 'LSTM-0.1-1.0-0.1', 'LSTM-0.1-1000.0-0.1'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D[model-param_str][cond] = [seed,time]\n",
    "lossD = build_dataD(gsdf,metric='loss',verb=False)\n",
    "print('num model conditions',len(lossD))\n",
    "lossD.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_loss_(ax,loss_arr,tag=None):\n",
    "  Nseeds,_ = loss_arr.shape\n",
    "  acc_arr = 1-loss_arr\n",
    "  for acc_seed in acc_arr:\n",
    "    ax.plot(acc_seed,lw=.05,c='k')\n",
    "  M = acc_arr.mean(0)\n",
    "  S = acc_arr.std(0)/np.sqrt(Nseeds)\n",
    "  ax.fill_between(range(200),M-S,M+S,alpha=.5,color='b')\n",
    "  ax.plot(M,lw=3,c='b')\n",
    "  ax.set_ylim(0.2,1)\n",
    "  return None\n",
    "\n",
    "def plt_loss(cond_dict,mse_dict,title):\n",
    "  f,ax = plt.subplots(2,1,figsize=(8,4),sharex=True)\n",
    "  for idx,(cond,arr) in enumerate(cond_dict.items()):\n",
    "    plt_loss_(ax[idx],arr)\n",
    "    ax[idx].plot(hdf.loc[:,\"%s mean\"%cond],color='red',lw=3)\n",
    "    ax[idx].set_title(\"%s mse%f\"%(title,mse_dict[cond]))\n",
    "  total_mse = np.sum([i for i in mse_dict.values()])\n",
    "  plt.savefig('figures/%s/acc/mse%.4f-acc-%s.png'%(gs_name,total_mse,title))\n",
    "  plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(cond_dict):\n",
    "  D = {}\n",
    "  for cond,loss_arr in cond_dict.items():\n",
    "    acc_arr = 1-loss_arr\n",
    "    semM = acc_arr.mean(0)\n",
    "    humanM = hdf.loc[:,'%s mean'%cond]\n",
    "    D[cond] = np.mean((semM-humanM)**2)\n",
    "  return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM-0.01-0.01-0.1 {'blocked': 0.012748805862756743, 'interleaved': 0.05016689576544213}\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "for model_param,cond_dict in lossD.items():\n",
    "  mse = calc_mse(cond_dict)\n",
    "  title = model_param\n",
    "  mse = calc_mse(cond_dict)\n",
    "  print(model_param,mse)\n",
    "  L.append({'model':model_param,'mse':mse})\n",
    "  plt_loss(cond_dict,mse,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# schema inference analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_D = build_dataD(gsdf,metric='curriculum',verb=False)\n",
    "actsch_D = build_dataD(gsdf,metric='active_schema',verb=False)\n",
    "k_ = list(actsch_D.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = 'blocked'\n",
    "curr_arr = curr_D[k_][cond]\n",
    "actsch_arr = actsch_D[k_][cond]\n",
    "\n",
    "actsch_arr\n",
    "curr_arr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
